import pytest
import sys
import os
from unittest.mock import Mock, patch, MagicMock
import time

# Add the parent directory to the path so we can import the modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from base import BaseLLM
from factory import get_llm
from logging_mixin import LoggingMixin

class DummyLLM(BaseLLM):
    def chat(self, messages: list[dict], **kwargs) -> str:
        return "Test response"

class TestLoggingMixin:
    """Test the LoggingMixin functionality"""
    
    def setup_method(self):
        self.mixin = LoggingMixin()
    
    @patch('logging_mixin.logger')
    def test_log_call_start(self, mock_logger):
        start_time = self.mixin.log_call_start("openai", "gpt-4", 2)
        
        mock_logger.info.assert_called_once_with("Calling openai/gpt-4 with 2 message(s)")
        assert isinstance(start_time, float)
        assert start_time <= time.time()
    
    @patch('logging_mixin.logger')
    def test_log_call_end(self, mock_logger):
        start_time = time.time() - 1.5  # Simulate 1.5 seconds ago
        self.mixin.log_call_end("anthropic", "claude-3-sonnet", start_time)
        
        mock_logger.info.assert_called_once()
        call_args = mock_logger.info.call_args[0][0]
        assert "anthropic/claude-3-sonnet response received in" in call_args
        assert "seconds" in call_args
    
    @patch('logging_mixin.logger')
    def test_log_token_usage_with_usage(self, mock_logger):
        usage = {
            "prompt_tokens": 10,
            "completion_tokens": 20,
            "total_tokens": 30
        }
        self.mixin.log_token_usage("openai", usage)
        
        mock_logger.info.assert_called_once_with(
            "openai - Prompt tokens: 10, Completion tokens: 20, Total: 30"
        )
    
    @patch('logging_mixin.logger')
    def test_log_token_usage_without_usage(self, mock_logger):
        self.mixin.log_token_usage("gemini", {})
        
        mock_logger.warning.assert_called_once_with(
            "gemini - Token usage information not available."
        )
    
    @patch('logging_mixin.logger')
    def test_log_provider_init(self, mock_logger):
        self.mixin.log_provider_init("openai", "gpt-4")
        
        mock_logger.info.assert_called_once_with(
            "Initialized openai wrapper with model: gpt-4"
        )

class TestBaseLLM:
    """Test the abstract base class"""
    
    def test_dummy_llm_chat(self):
        dummy = DummyLLM()
        response = dummy.chat([{"role": "user", "content": "Hello"}])
        assert isinstance(response, str)
        assert response == "Test response"

class TestFactory:
    """Test the factory pattern implementation"""
    
    def test_factory_openai(self, monkeypatch):
        class MockOpenAIWrapper:
            def __init__(self, api_key, model):
                self.api_key = api_key
                self.model = model
                self.provider = "openai"
            def chat(self, messages, **kwargs):
                return "Mocked OpenAI response"

        import factory
        monkeypatch.setattr(factory, "OpenAIWrapper", MockOpenAIWrapper)
        config = {"api_key": "test", "model": "gpt-4"}
        llm = get_llm("openai", config)
        assert llm.chat([{"role": "user", "content": "Hi"}]) == "Mocked OpenAI response"
        assert llm.model == "gpt-4"
        assert llm.provider == "openai"

    def test_factory_anthropic(self, monkeypatch):
        class MockAnthropicWrapper:
            def __init__(self, api_key, model):
                self.api_key = api_key
                self.model = model
                self.provider = "anthropic"
            def chat(self, messages, **kwargs):
                return "Mocked Anthropic response"

        import factory
        monkeypatch.setattr(factory, "ClaudeWrapper", MockAnthropicWrapper)
        config = {"api_key": "test", "model": "claude-3-sonnet-20240229"}
        llm = get_llm("anthropic", config)
        assert llm.chat([{"role": "user", "content": "Hi"}]) == "Mocked Anthropic response"
        assert llm.model == "claude-3-sonnet-20240229"
        assert llm.provider == "anthropic"

    def test_factory_gemini(self, monkeypatch):
        class MockGeminiWrapper:
            def __init__(self, api_key, model):
                self.api_key = api_key
                self.model = model
                self.provider = "gemini"
            def chat(self, messages, **kwargs):
                return "Mocked Gemini response"

        import factory
        monkeypatch.setattr(factory, "GeminiWrapper", MockGeminiWrapper)
        config = {"api_key": "test", "model": "gemini-pro"}
        llm = get_llm("gemini", config)
        assert llm.chat([{"role": "user", "content": "Hi"}]) == "Mocked Gemini response"
        assert llm.model == "gemini-pro"
        assert llm.provider == "gemini"

    def test_factory_grok(self, monkeypatch):
        class MockGrokWrapper:
            def __init__(self, api_key, model, base_url):
                self.api_key = api_key
                self.model = model
                self.base_url = base_url
                self.provider = "grok"
            def chat(self, messages, **kwargs):
                return "Mocked Grok response"

        import factory
        monkeypatch.setattr(factory, "GrokWrapper", MockGrokWrapper)
        config = {"api_key": "test", "model": "grok-beta", "base_url": "https://api.x.ai/v1"}
        llm = get_llm("grok", config)
        assert llm.chat([{"role": "user", "content": "Hi"}]) == "Mocked Grok response"
        assert llm.model == "grok-beta"
        assert llm.provider == "grok"
        assert llm.base_url == "https://api.x.ai/v1"

    def test_factory_invalid_provider(self):
        config = {"api_key": "test"}
        with pytest.raises(ValueError, match="Unsupported LLM provider"):
            get_llm("unknown", config)

    def test_factory_default_models(self, monkeypatch):
        """Test that default models are used when not specified"""
        class MockWrapper:
            def __init__(self, api_key, model):
                self.model = model
        
        import factory
        monkeypatch.setattr(factory, "OpenAIWrapper", MockWrapper)
        
        config = {"api_key": "test"}  # No model specified
        llm = get_llm("openai", config)
        assert llm.model == "gpt-4"  # Should use default

class TestWrapperInitialization:
    """Test wrapper initialization and provider attributes"""

    def test_openai_wrapper_initialization(self):
        """Test that OpenAI wrapper can be initialized with proper parameters"""
        from openai_wrapper import OpenAIWrapper
        
        # Mock the OpenAI client to avoid actual API calls
        with patch('openai_wrapper.OpenAI') as mock_openai:
            mock_client = Mock()
            mock_openai.return_value = mock_client
            
            with patch.object(LoggingMixin, 'log_provider_init') as mock_log:
                wrapper = OpenAIWrapper(api_key="test-key", model="gpt-4")
                
                assert wrapper.model == "gpt-4"
                assert wrapper.provider == "openai"
                assert hasattr(wrapper, 'client')
                mock_log.assert_called_once_with("openai", "gpt-4")

    def test_anthropic_wrapper_initialization(self):
        """Test that Anthropic wrapper can be initialized with proper parameters"""
        from anthropic_wrapper import ClaudeWrapper
        
        with patch('anthropic_wrapper.anthropic.Anthropic') as mock_anthropic:
            mock_client = Mock()
            mock_anthropic.return_value = mock_client
            
            with patch.object(LoggingMixin, 'log_provider_init') as mock_log:
                wrapper = ClaudeWrapper(api_key="test-key", model="claude-3-sonnet-20240229")
                
                assert wrapper.model == "claude-3-sonnet-20240229"
                assert wrapper.provider == "anthropic"
                assert hasattr(wrapper, 'client')
                mock_log.assert_called_once_with("anthropic", "claude-3-sonnet-20240229")

    def test_gemini_wrapper_initialization(self):
        """Test that Gemini wrapper can be initialized with proper parameters"""
        from gemini_wrapper import GeminiWrapper
        
        with patch('gemini_wrapper.genai.Client') as mock_genai:
            mock_client = Mock()
            mock_genai.return_value = mock_client
            
            with patch.object(LoggingMixin, 'log_provider_init') as mock_log:
                wrapper = GeminiWrapper(api_key="test-key", model="gemini-pro")
                
                assert wrapper.model == "gemini-pro"
                assert wrapper.provider == "gemini"
                assert hasattr(wrapper, 'client')
                mock_log.assert_called_once_with("gemini", "gemini-pro")

    def test_grok_wrapper_initialization(self):
        """Test that Grok wrapper can be initialized with proper parameters"""
        from grok_wrapper import GrokWrapper
        
        with patch.object(LoggingMixin, 'log_provider_init') as mock_log:
            wrapper = GrokWrapper(api_key="test-key", model="grok-1")
            
            assert wrapper.model == "grok-1"
            assert wrapper.provider == "grok"
            assert wrapper.api_key == "test-key"
            mock_log.assert_called_once_with("grok", "grok-1")

class TestWrapperChatMethods:
    """Test the chat methods of each wrapper with proper mocking"""

    def test_openai_chat_method(self):
        """Test OpenAI chat method with logging"""
        from openai_wrapper import OpenAIWrapper
        
        # Mock response structure
        mock_usage = Mock()
        mock_usage.model_dump.return_value = {
            "prompt_tokens": 10, "completion_tokens": 20, "total_tokens": 30
        }
        
        mock_message = Mock()
        mock_message.content = "Test response"
        
        mock_choice = Mock()
        mock_choice.message = mock_message
        
        mock_response = Mock()
        mock_response.choices = [mock_choice]
        mock_response.usage = mock_usage
        
        with patch('openai_wrapper.OpenAI') as mock_openai_class:
            mock_client = Mock()
            mock_client.chat.completions.create.return_value = mock_response
            mock_openai_class.return_value = mock_client
            
            with patch.object(LoggingMixin, 'log_call_start') as mock_start, \
                 patch.object(LoggingMixin, 'log_call_end') as mock_end, \
                 patch.object(LoggingMixin, 'log_token_usage') as mock_usage_log, \
                 patch.object(LoggingMixin, 'log_provider_init'):
                
                wrapper = OpenAIWrapper(api_key="test-key", model="gpt-4")
                messages = [{"role": "user", "content": "Hello"}]
                response = wrapper.chat(messages)
                
                assert response == "Test response"
                mock_start.assert_called_once_with("openai", "gpt-4", 1)
                mock_end.assert_called_once()
                mock_usage_log.assert_called_once()

    def test_grok_chat_method(self):
        """Test Grok chat method with proper API mocking"""
        from grok_wrapper import GrokWrapper
        
        # Mock response structure (same as OpenAI since Grok uses compatible API)
        mock_usage = Mock()
        mock_usage.prompt_tokens = 10
        mock_usage.completion_tokens = 20
        mock_usage.total_tokens = 30
        
        mock_message = Mock()
        mock_message.content = "Grok response"
        
        mock_choice = Mock()
        mock_choice.message = mock_message
        
        mock_response = Mock()
        mock_response.choices = [mock_choice]
        mock_response.usage = mock_usage
        
        with patch('grok_wrapper.OpenAI') as mock_openai_class:
            mock_client = Mock()
            mock_client.chat.completions.create.return_value = mock_response
            mock_openai_class.return_value = mock_client
            
            with patch.object(LoggingMixin, 'log_call_start') as mock_start, \
                 patch.object(LoggingMixin, 'log_call_end') as mock_end, \
                 patch.object(LoggingMixin, 'log_token_usage') as mock_usage_log, \
                 patch.object(LoggingMixin, 'log_provider_init'):
                
                wrapper = GrokWrapper(api_key="test-key", model="grok-beta")
                messages = [{"role": "user", "content": "Hello"}]
                response = wrapper.chat(messages)
                
                assert response == "Grok response"
                mock_start.assert_called_once_with("grok", "grok-beta", 1)
                mock_end.assert_called_once()
                mock_usage_log.assert_called_once()
                
                # Verify OpenAI client was initialized with correct parameters
                mock_openai_class.assert_called_once_with(
                    api_key="test-key",
                    base_url="https://api.x.ai/v1"
                )

class TestErrorHandling:
    """Test error handling scenarios"""
    
    def test_factory_with_missing_api_key(self):
        """Test factory behavior with missing API key"""
        config = {"model": "gpt-4"}  # Missing api_key
        
        with pytest.raises(KeyError):
            get_llm("openai", config)
    
    def test_factory_logging_on_instantiation(self):
        """Test that factory logs provider instantiation"""
        with patch('factory.logger') as mock_logger, \
             patch('factory.OpenAIWrapper') as mock_wrapper:
            
            config = {"api_key": "test", "model": "gpt-4"}
            get_llm("openai", config)
            
            mock_logger.info.assert_called_with("Instantiating OpenAIWrapper")

if __name__ == "__main__":
    pytest.main([__file__, "-v"])